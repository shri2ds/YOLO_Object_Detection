"""
YOLO v1 Dataset Implementation (Pothole Optimized)

This module handles the loading and transformation of the Pothole Detection Dataset.
It is responsible for converting raw image pixels and text annotations into the
specific 3D Tensor format required by the YOLO v1 architecture.

Engineering Note on Tensor Shape for Single Class (Potholes):
-------------------------------------------------------------
Standard YOLO (Pascal VOC) uses C=20, resulting in a depth of 30.
Since we are optimizing for a single class (Pothole), we set C=1.
This reduces the target tensor depth to 6:
[Class(0), Confidence(1), x(2), y(3), w(4), h(5)]
"""

import torch
import os
import pandas as pd
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches


class YOLODataset(torch.utils.data.Dataset):
    def __init__(self, csv_file, img_dir, label_dir, S=7, B=2, C=1, transform=None):
        """
        Args:
            csv_file (str): Path to the CSV file generated by generate_csv.py.
            img_dir (str): Root directory for images.
            label_dir (str): Root directory for text labels.
            S (int): Grid size (default 7 for 7x7 split).
            B (int): Number of bounding boxes per cell (default 2).
                     Note: Only used for model output shape, not target shape.
            C (int): Number of classes (default 1 for Potholes).
            transform (callable, optional): PyTorch transforms for data augmentation.
        """
        self.annotations = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.label_dir = label_dir
        self.transform = transform
        self.S = S
        self.B = B
        self.C = C

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, index):
        """
        Fetches a single sample and converts it to a YOLO Target Tensor.

        Logic Flow:
        1. Load Image (PIL) and Label (Text).
        2. Parse bounding boxes (normalized 0-1).
        3. Determine which Grid Cell (i, j) is responsible for the object.
        4. Calculate offsets relative to that specific cell (0-1 within cell).
        5. Populate the Target Tensor (S, S, C+5).

        Returns:
            image (Tensor): The image pixels.
            target (Tensor): The 7x7x6 Truth Tensor.
        """
        # Construct Path
        # CSV now contains correct paths (data/images/... and data/labels/...)
        label_path = os.path.join(self.label_dir, self.annotations.iloc[index, 1]) if self.label_dir else self.annotations.iloc[index, 1]
        img_path = os.path.join(self.img_dir, self.annotations.iloc[index, 0]) if self.img_dir else self.annotations.iloc[index, 0]

        # Load Path
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)

        # Parse Label File
        # Expected Format per line: [class_id, x_center, y_center, width, height]
        boxes = []
        with open(label_path) as f:
            for line in f.readlines():
                class_label, x, y, w, h = [
                    float(x) if float(x) != int(float(x)) else int(x)
                    for x in line.replace("\n", "").split()
                ]
                boxes.append([class_label, x, y, w, h])

        # ENCODE TO GRID TENSOR
        # Target Shape: (7, 7, 6) for C=1
        # [Class(0), Confidence(1), x(2), y(3), w(4), h(5)]
        target = torch.zeros((self.S, self.S, self.C + 5))

        for box in boxes:
            class_label, x, y, w, h = box

            # Grid Calculation
            i, j = int(self.S * y), int(self.S * x)
            x_cell = self.S * x - j
            y_cell = self.S * y - i
            width_cell, height_cell = (w * self.S, h * self.S)

            # Assign to Grid
            # Check Index 1 for Confidence
            if target[i, j, 1] == 0:
                target[i, j, 1] = 1  # Confidence = 1

                # Correct Slice [2:6] covers indices 2,3,4,5 (Length 4)
                target[i, j, 2:6] = torch.tensor([x_cell, y_cell, width_cell, height_cell])

                # Class Label (Always 0 for Pothole)
                target[i, j, 0] = 1

        return image, target


def plot_image(image, boxes, save_path=None):
    """
    Visualizes the image and draws the bounding boxes.

    Args:
        image (PIL.Image): The input image.
        boxes (list): List of decoded boxes [x, y, w, h].
        save_path (str, optional): If provided, saves the plot to disk.
    """
    fig, ax = plt.subplots(1)
    ax.imshow(image)

    img_width, img_height = image.size[0], image.size[1]

    for box in boxes:
        box_x, box_y, box_w, box_h = box

        # Convert Center-Based (x,y) to Corner-Based (x,y) for Matplotlib
        lower_left_x = (box_x - box_w / 2) * img_width
        lower_left_y = (box_y - box_h / 2) * img_height

        # Create a Rectangle patch
        rect = patches.Rectangle(
            (lower_left_x, lower_left_y),
            box_w * img_width,
            box_h * img_height,
            linewidth=2,
            edgecolor='r',
            facecolor='none'
        )
        ax.add_patch(rect)

    # Save BEFORE showing
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… Image saved to {save_path}")

    plt.show()


def convert_cell_boxes(predictions, S=7):
    """
    Decodes the Grid Tensor (7, 7, 6) back to Global Coordinates.
    Reverses the logic of __getitem__.

    Args:
        predictions (Tensor): Input tensor of shape (S, S, 6).
        S (int): Grid size.

    Returns:
        list: List of [x, y, w, h] in global normalized format.
    """
    boxes = []

    for i in range(S):
        for j in range(S):
            # Check Confidence at Index 1
            if predictions[i, j, 1] == 1:
                # Indices: x(2), y(3), w(4), h(5)
                x_cell = predictions[i, j, 2]
                y_cell = predictions[i, j, 3]
                w_cell = predictions[i, j, 4]
                h_cell = predictions[i, j, 5]

                # Reverse Math
                x = (x_cell + j) / S
                y = (y_cell + i) / S
                w = w_cell / S
                h = h_cell / S

                boxes.append([x, y, w, h])

    return boxes


if __name__ == "__main__":
    # Setup
    CSV_FILE = "data/train.csv"
    IMG_DIR = ""
    LABEL_DIR = ""

    # Initialize Dataset
    # C=1 implies we are strictly detecting Potholes
    dataset = YOLODataset(
        csv_file=CSV_FILE, img_dir=IMG_DIR, label_dir=LABEL_DIR,
        S=7, B=2, C=1  # C=1 for Potholes
    )

    print(f"Dataset Length: {len(dataset)}")

    # Fetch a specific sample (e.g., Index 10)
    img, target = dataset[10]

    print(f"Image Shape: {img.size}")
    print(f"Target Tensor Shape: {target.shape}")  # Expect (7, 7, 6)

    # Decode
    detected_boxes = convert_cell_boxes(target, S=7)
    print(f"Decoded {len(detected_boxes)} box(es). Coords: {detected_boxes}")

    # Visualize & Save
    os.makedirs("assets", exist_ok=True)
    plot_image(img, detected_boxes, save_path="assets/pothole_demo.png")
